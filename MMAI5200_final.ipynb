{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiu04/Data-Science/blob/main/MMAI5200_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "50K07bHO5NnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dijkstra(G, start, end):\n",
        "\n",
        "    # Initialize the set of vertices Q and the distance array d\n",
        "    unvisted = set(G.keys()) # All vertices in the graph G\n",
        "    ## for all vertices v in unvisted, set the distance to infinite\n",
        "    d = {v: float('infinity') for v in unvisted}\n",
        "    ## staring point with distance of 0\n",
        "    d[start] = 0\n",
        "    ## store the predecessors, none for all vertices in initialization\n",
        "    predecessors = {v: None for v in unvisted}\n",
        "\n",
        "\n",
        "    while unvisted:\n",
        "        current = None\n",
        "        ## set min distance to infinity\n",
        "        min_distance = float('infinity')\n",
        "        ## Select the vertex current with the minimum d[u] value in unvisited\n",
        "        for vertex in unvisted:\n",
        "            if d[vertex] < min_distance:\n",
        "                min_distance = d[vertex]\n",
        "                current = vertex\n",
        "        ## remove current vertex from unvisited\n",
        "        unvisted.remove(current)\n",
        "\n",
        "        # Break the loop if the smallest distance is infinity or\n",
        "        # if the destination is found\n",
        "        if d[current] == float('infinity') or current == end:\n",
        "            break\n",
        "\n",
        "        # Relax the edges from u to its neighbors\n",
        "        for v, distance in G[current].items():\n",
        "            if v in unvisted and d[current] + distance < d[v]:\n",
        "                d[v] = d[current] + distance\n",
        "                predecessors[v] = current\n",
        "\n",
        "    # Reconstruct the shortest path from end to start\n",
        "    path = []\n",
        "    current_vertex = end\n",
        "    while current_vertex is not None:\n",
        "        path.insert(0, current_vertex)\n",
        "        current_vertex = predecessors[current_vertex]\n",
        "\n",
        "    return path, d[end]\n",
        "\n",
        "\n",
        "graph = {\n",
        "    'Origin': {'Vaughan': 20, 'Richmond Hill': 30, 'Markham': 25},\n",
        "    'Vaughan': {'Richmond Hill': 5, 'North York': 35},\n",
        "    'Richmond Hill': {'Richmond Hill': 10 , 'Markham': 25, 'North York': 20},\n",
        "    'Markham': {'North York': 25, 'Destination': 50},\n",
        "    'North York': {'Destination': 30},\n",
        "    'Destination': {}}\n",
        "\n",
        "shortest_distances = dijkstra(graph, 'Origin', 'Destination')\n",
        "print(\"Shortest distances from Origin\", \":\", shortest_distances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-dsHypNjrtD",
        "outputId": "092898a6-0906-466f-8fe7-c530db1bc2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest distances from Origin : (['Origin', 'Markham', 'Destination'], 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "6oe_8zZc5Q6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#part (a)\n",
        "import numpy as np\n",
        "\n",
        "# States and rewards\n",
        "states = [1, 2, 3]\n",
        "profits = {1: 500, 2: 1000, 3: 3000}\n",
        "advertising_cost = 100\n",
        "discount_factor = 0.9\n",
        "\n",
        "# Transition probabilities\n",
        "transitions_no_ad = {\n",
        "    1: {1: 0.4, 2: 0.6, 3: 0},\n",
        "    2: {1: 0.3, 2: 0.4, 3: 0.3},\n",
        "    3: {1: 0, 2: 0.6, 3: 0.4}\n",
        "}\n",
        "\n",
        "transitions_ad = {\n",
        "    1: {1: 0.1, 2: 0.9, 3: 0},\n",
        "    2: {1: 0.1, 2: 0.6, 3: 0.3},\n",
        "    3: {1: 0, 2: 0.35, 3: 0.65}\n",
        "}\n",
        "\n",
        "# Value iteration function\n",
        "def value_iteration(states, transitions_no_ad, transitions_ad, profits, advertising_cost, discount_factor, theta=0.0001):\n",
        "    V = {s: 0 for s in states} # Initialize value for each state\n",
        "    policy = {s: None for s in states} # Initialize policy\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in states:\n",
        "            v = V[s]\n",
        "\n",
        "            # Calculate the value of not advertising and advertising\n",
        "            no_ad_value = sum(transitions_no_ad[s][s_prime] * (profits[s_prime] + discount_factor * V[s_prime]) for s_prime in states)\n",
        "            ad_value = sum(transitions_ad[s][s_prime] * (profits[s_prime] - advertising_cost + discount_factor * V[s_prime]) for s_prime in states)\n",
        "\n",
        "            # Choose the best action\n",
        "            V[s] = max(no_ad_value, ad_value)\n",
        "\n",
        "            delta = max(delta, abs(v - V[s]))\n",
        "        if delta < 0.05: # A small threshold for convergence\n",
        "            break\n",
        "\n",
        "    # Derive policy from value function\n",
        "    for s in states:\n",
        "        no_ad_value = sum(transitions_no_ad[s][s_prime] * (profits[s_prime] + discount_factor * V[s_prime]) for s_prime in states)\n",
        "        ad_value = sum(transitions_ad[s][s_prime] * (profits[s_prime] - advertising_cost + discount_factor * V[s_prime]) for s_prime in states)\n",
        "\n",
        "        policy[s] = 'A' if ad_value > no_ad_value else 'N'\n",
        "\n",
        "    return policy, V\n",
        "\n",
        "policy, V = value_iteration(states, transitions_no_ad, transitions_ad, profits, advertising_cost, discount_factor)\n",
        "\n",
        "print(\"Optimal policy:\", policy)\n",
        "print(\"Value function:\", V)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_iSchxk9czS",
        "outputId": "dd292b93-a022-43a4-ac5c-b38e08bc875b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal policy: {1: 'A', 2: 'A', 3: 'A'}\n",
            "Value function: {1: 16021.006292419286, 2: 16949.5764974934, 3: 18166.485062498927}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#part (b)\n",
        "import numpy as np\n",
        "\n",
        "# Define the states and corresponding profits\n",
        "states = [1, 2, 3]\n",
        "profits = {1: 500, 2: 1000, 3: 3000}\n",
        "advertising_cost = 100\n",
        "discount_factor = 0.9\n",
        "\n",
        "# Transition probabilities for not advertising\n",
        "transition_no_ad = {\n",
        "    1: {1: 0.4, 2: 0.6, 3: 0},\n",
        "    2: {1: 0.3, 2: 0.4, 3: 0.3},\n",
        "    3: {1: 0, 2: 0.6, 3: 0.4}\n",
        "}\n",
        "\n",
        "# Transition probabilities for advertising\n",
        "transition_ad = {\n",
        "    1: {1: 0.1, 2: 0.9, 3: 0},\n",
        "    2: {1: 0.1, 2: 0.6, 3: 0.3},\n",
        "    3: {1: 0, 2: 0.35, 3: 0.65}\n",
        "}\n",
        "\n",
        "# Policy iteration algorithm\n",
        "def policy_iteration(states, transition_no_ad, transition_ad, profits, advertising_cost, discount_factor):\n",
        "    # Initial policy is not to advertise in any state\n",
        "    policy = {state: 'N' for state in states}\n",
        "    V = {state: 0 for state in states}\n",
        "\n",
        "    is_policy_stable = False\n",
        "    while not is_policy_stable:\n",
        "        # Policy Evaluation\n",
        "        while True:\n",
        "            delta = 0\n",
        "            for s in states:\n",
        "                v = V[s]\n",
        "                # Calculate value for current policy\n",
        "                transition_prob = transition_ad[s] if policy[s] == 'A' else transition_no_ad[s]\n",
        "                V[s] = sum(transition_prob[s_prime] * (profits[s_prime] - (advertising_cost if policy[s] == 'A' else 0) \\\n",
        "                                                       + discount_factor * V[s_prime]) for s_prime in states)\n",
        "                delta = max(delta, abs(v - V[s]))\n",
        "            if delta < 0.05: # A small threshold for convergence\n",
        "                break\n",
        "\n",
        "        # Policy Improvement\n",
        "        is_policy_stable = True\n",
        "        for s in states:\n",
        "            old_action = policy[s]\n",
        "\n",
        "            # Check if advertising in state s is better\n",
        "            value_no_ad = sum(transition_no_ad[s][s_prime] * (profits[s_prime] + discount_factor * V[s_prime]) for s_prime in states)\n",
        "            value_ad = sum(transition_ad[s][s_prime] * (profits[s_prime] - advertising_cost + discount_factor * V[s_prime]) for s_prime in states)\n",
        "\n",
        "            policy[s] = 'A' if value_ad > value_no_ad else 'N'\n",
        "\n",
        "            if old_action != policy[s]:\n",
        "                is_policy_stable = False\n",
        "\n",
        "    return policy, V\n",
        "\n",
        "policy, V = policy_iteration(states, transition_no_ad, transition_ad, profits, advertising_cost, discount_factor)\n",
        "\n",
        "print(\"Optimal policy:\", policy)\n",
        "print(\"Value function:\", V)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y1-J6DU7cCZ",
        "outputId": "f89f9dd7-d0bb-48b5-e2ce-0ea51a59eafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal policy: {1: 'A', 2: 'A', 3: 'A'}\n",
            "Value function: {1: 16021.01748180916, 2: 16949.587366370146, 3: 18166.495350059486}\n"
          ]
        }
      ]
    }
  ]
}